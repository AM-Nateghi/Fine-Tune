{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f17f3-29d7-4857-89de-044ecd668d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate rouge_score loralib bitsandbytes scikit-learn peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d31a2-8f75-4834-85f5-3252ce57821f",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4592a74-2781-4034-8a9c-e1e08a5b3ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding)\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ef3bf-f36d-4795-a648-222a3266a355",
   "metadata": {},
   "source": [
    "## Logging In to Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef00ffd-b753-4ed3-8cc6-32564b5037bc",
   "metadata": {},
   "source": [
    "**It is necessary for local fine-tuning of Gemma**\n",
    "\n",
    "    Create an Account: Visit https://huggingface.co/ and sign up for a free account.\n",
    "    Generate an Access Token: Go to your profile settings (top right corner) -> Access Tokens -> Create a new token. This token grants access to Hugging Face features like uploading fine-tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d312ba2-b401-4826-b5f2-438d0d0d84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy toj=ken from https://huggingface.co/settings/tokens\n",
    "import huggingface_hub\n",
<<<<<<< HEAD
    "hf_token = 'hf_...' # put your User Access Tokens here\n",
=======
    "hf_token = 'hf_..' # put your User Access Tokens here\n",
>>>>>>> a3bb8d4 (_catch the secret error)
    "# ابتدا login کنید\n",
    "huggingface_hub.login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99208c8e-43a5-495a-8ac3-b2003a638d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1muser: \u001b[0m AM-Nateghi\n"
     ]
    }
   ],
   "source": [
    "!hf auth whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff1040-5845-4ac8-a2f1-0718b964d5f9",
   "metadata": {},
   "source": [
    "## load the imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7bcd83-0cea-4bc0-97f3-82d1570ebf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071f6da9-4008-4ac6-9ee5-7a773c305721",
   "metadata": {},
   "source": [
    "### reduce the dataset (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41432ec-f5d7-4fa5-8897-dc3e04e868cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "reduction_rate    = 0.1\n",
    "num_train_to_keep = int(reduction_rate * dataset_imdb[\"train\"].num_rows)\n",
    "num_test_to_keep  = int(reduction_rate * dataset_imdb[\"test\"].num_rows)\n",
    "\n",
    "def select_random_indices(dataset, num_to_keep):\n",
    "    indices = list(range(dataset.num_rows))\n",
    "    random.shuffle(indices)\n",
    "    return indices[:num_to_keep]\n",
    "\n",
    "train_indices = select_random_indices(dataset_imdb[\"train\"], num_train_to_keep)\n",
    "test_indices  = select_random_indices(dataset_imdb[\"test\"], num_test_to_keep)\n",
    "\n",
    "dataset_imdb  = DatasetDict({\n",
    "    \"train\": dataset_imdb[\"train\"].select(train_indices),\n",
    "    \"test\": dataset_imdb[\"test\"].select(test_indices),\n",
    "})\n",
    "\n",
    "dataset_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e8578-e5c2-4896-8c0b-b7e050f86797",
   "metadata": {},
   "source": [
    "## Tokenization and Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fbff86-2698-4efb-8d02-504992db73e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size of the model google/gemma-2b-it: 256000\n"
     ]
    }
   ],
   "source": [
    "model_id  = \"google/gemma-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(f'Vocab size of the model {model_id}: {len(tokenizer.get_vocab())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "480f9481-5928-4490-aa2d-c6b7fa875a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True,  max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89275a4b-6eef-4522-98c5-e04255fc17a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2500/2500 [00:00<00:00, 6470.83 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:00<00:00, 7601.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_imdb = dataset_imdb.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea2d16-291e-419c-8b56-5a5166688e05",
   "metadata": {},
   "source": [
    "This creates a new dataset named tokenized_imdb with additional columns:\n",
    "\n",
    "    input_ids: Numerical representation of the text using tokenizer vocabulary.\n",
    "    attention_mask: Mask to indicate valid elements in padded sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c3a559c-0a94-4c5f-99c4-bea18a446e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df264373-6619-4663-b404-4b0785a65ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "182\n",
      "180\n",
      "109\n",
      "198\n",
      "229\n",
      "512\n",
      "346\n",
      "80\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(tokenized_imdb['train'][i]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700bf84e-2927-40fc-b3ab-270bd3f6bba1",
   "metadata": {},
   "source": [
    "## Label Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4902a6b-8338-48d8-a665-9c52f8d2e7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NEGATIVE': 0, 'POSITIVE': 1}\n"
     ]
    }
   ],
   "source": [
    "# طبق گفته جناب تصدیقی از آنجایی که برنامه نویسان همواره عاشق هستند مگر اینکه خلافش ثابت بشه باید اینجا دومی رو بر حسب اولی بسازیم! هه\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29a967c-df8b-42a2-ba04-d58002bf6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3c1d9-f068-48b2-9de3-236f8462bcd7",
   "metadata": {},
   "source": [
    "## Defining Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3f4ac62-8e35-4ad7-b822-ced70b46b9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 4.20kB [00:00, 9.30MB/s]\n",
      "Downloading builder script: 6.79kB [00:00, 16.8MB/s]\n",
      "Downloading builder script: 7.56kB [00:00, 20.4MB/s]\n",
      "Downloading builder script: 7.38kB [00:00, 5.63MB/s]\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)  # Convert probabilities to predicted labels\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3902181-0351-4c63-8b64-a41185748ad9",
   "metadata": {},
   "source": [
    "## Quantization Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9be0a0cc-420c-449b-92d4-2e89b4597847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRa Configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enables 4-bit quantization\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for potentially higher accuracy (optional)\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Quantization type (specifics depend on hardware and library, now, our library is QLoRa)\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # Compute dtype for improved efficiency (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0517566-1c0c-4e42-bc73-2c8dbd8b885d",
   "metadata": {},
   "source": [
    "## Loading GEMMA-2b in 4-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48cdb6-56f5-47e0-a193-fc6b8d5891fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-10-02T11:05:08.874189Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/0fd705d60b7c5b9d9c81a6652898998592ae588c337e14e003696e96c673d93f?X-Xet-Signed-Range=bytes%3D0-58588407&X-Xet-Session-Id=01K6J9HR3Q9F6JE5VF0FZS3YAM&Expires=1759406708&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC8wZmQ3MDVkNjBiN2M1YjlkOWM4MWE2NjUyODk4OTk4NTkyYWU1ODhjMzM3ZTE0ZTAwMzY5NmU5NmM2NzNkOTNmP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNTg1ODg0MDcmWC1YZXQtU2Vzc2lvbi1JZD0wMUs2SjlIUjNROUY2SkU1VkYwRlpTM1lBTSIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTQwNjcwOH19fV19&Signature=uumfWN5UHZxEL3IuBh5ekHiGBiWu01xMX0j5uJallXn-qiTLor0nZL~4fyh348zwNzOlYjMeO1d-Cr0bDxXhFFrpCwZgVj14SoaQlqrOMjtegBBZPTEXOvr8LNWuipM2pOGGz1sPvGnP~KDqZxJmirkKq2J2IsW-uPPEVTXge70Kdp--n1oMQT4awFcjPViLkf15nr6ZxKbstrmQ7yXBcgMYxgKASgTDtQtu2h1qnJc3efK6Rwm3f-tQDRF2rIooobE5RTq7kVxHxhT0cWdaLQCWHgbV9I1785RpifvZ1AOPHQFeNkbbwqsDYwWdH-luPmCMHSIO-92-Tf1Hl9lgeQ__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(Connect, Custom { kind: Other, error: Os { code: 104, kind: ConnectionReset, message: \"Connection reset by peer\" } }) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:233\n",
      "\n",
      "  \u001b[2m2025-10-02T11:05:08.874212Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 2.053492925s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n",
      "  \u001b[2m2025-10-02T11:05:09.391630Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/4b8b5b8a37efbee0b2284b9fbade47c740487f297ccb513176e2a703111e2f2f?X-Xet-Signed-Range=bytes%3D0-58540765&X-Xet-Session-Id=01K6J9HR3Q9F6JE5VF0FZS3YAM&Expires=1759406708&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC80YjhiNWI4YTM3ZWZiZWUwYjIyODRiOWZiYWRlNDdjNzQwNDg3ZjI5N2NjYjUxMzE3NmUyYTcwMzExMWUyZjJmP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNTg1NDA3NjUmWC1YZXQtU2Vzc2lvbi1JZD0wMUs2SjlIUjNROUY2SkU1VkYwRlpTM1lBTSIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTQwNjcwOH19fV19&Signature=WwRqEuFTg1G94ynAUI~wuIfnLgk1ck7WB3SOv1Rl8Ql8vUh5I2-RfaAkxJTZDFapnNLreo9ef8Fwa9Uv0A~s3cliDupvz0ArUNk37fMyBYW3BdZKIPXBGfCnugH6G1aBI45aNLiGe4hE88Qvs9SzLAL6Z76yx5hSZtCndSRb58ghL4FyRrm3~c1YIATMnI0k1LCrMISwgJFq-wkxsfuNGZ1dCGbMxBEFvUL2n-XXlWvVB1TYefJWzPhzt~wZNHPiQHxe9Nald10FFO4u1xcgbPaTboxhx2PLqyVi7mrtMDNmnkEoQreiNe5BFlgRWwdUmZ~RF8R0jraEx~vVDRM0kg__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(Connect, Custom { kind: Other, error: Os { code: 104, kind: ConnectionReset, message: \"Connection reset by peer\" } }) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:233\n",
      "\n",
      "  \u001b[2m2025-10-02T11:05:09.391655Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 1.190979039s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files:   0%|          | 0/2 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:51\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[32m     50\u001b[39m                   initargs=(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m     gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"google/gemma-2b-it\"\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of output labels (2 for binary sentiment classification)\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mid2label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mid2label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# {0: \"NEGATIVE\", 1: \"POSITIVE\"} \u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel2id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel2id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# {\"NEGATIVE\": 0, \"POSITIVE\": 1}\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# configuration for quantization \u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/transformers/modeling_utils.py:288\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    290\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/transformers/modeling_utils.py:5030\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5021\u001b[39m     gguf_file\n\u001b[32m   5022\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5023\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   5024\u001b[39m ):\n\u001b[32m   5025\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   5026\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5027\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5028\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m5030\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5032\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5034\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5035\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5036\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5037\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5038\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5039\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5040\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5041\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5043\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5046\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   5047\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5048\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5050\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5051\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/transformers/modeling_utils.py:1308\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1306\u001b[39m sharded_metadata = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[32m-> \u001b[39m\u001b[32m1308\u001b[39m     checkpoint_files, sharded_metadata = \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1322\u001b[39m     checkpoint_files = [resolved_archive_file] \u001b[38;5;28;01mif\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/transformers/utils/hub.py:1119\u001b[39m, in \u001b[36mget_checkpoint_shard_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m shard_filenames, sharded_metadata\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# At this stage pretrained_model_name_or_path is a model identifier on the Hub. Try to get everything from cache,\u001b[39;00m\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# or download the files\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m cached_filenames = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cached_filenames, sharded_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/transformers/utils/hub.py:493\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m         hf_hub_download(\n\u001b[32m    479\u001b[39m             path_or_repo_id,\n\u001b[32m    480\u001b[39m             filenames[\u001b[32m0\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    491\u001b[39m         )\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m         \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    508\u001b[39m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:332\u001b[39m, in \u001b[36msnapshot_download\u001b[39m\u001b[34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[39m\n\u001b[32m    330\u001b[39m         _inner_hf_hub_download(file)\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os.path.realpath(local_dir))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:69\u001b[39m, in \u001b[36mthread_map\u001b[39m\u001b[34m(fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/tqdm/contrib/concurrent.py:49\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m lock_name = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mlock_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name=lock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_lock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                      \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/thread.py:238\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:1147\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1149\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1150\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1151\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:1167\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1168\u001b[39m         lock.release()\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-10-02T11:05:43.170893Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://transfer.xethub.hf.co/xorbs/default/d8d22d69114fa627ca0e3fc36aea6ca86da0d06eaabc2980cd6864f7bd2853ca?X-Xet-Signed-Range=bytes%3D0-58467039&X-Xet-Session-Id=01K6J9HR3Q9F6JE5VF0FZS3YAM&Expires=1759406709&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC9kOGQyMmQ2OTExNGZhNjI3Y2EwZTNmYzM2YWVhNmNhODZkYTBkMDZlYWFiYzI5ODBjZDY4NjRmN2JkMjg1M2NhP1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDAtNTg0NjcwMzkmWC1YZXQtU2Vzc2lvbi1JZD0wMUs2SjlIUjNROUY2SkU1VkYwRlpTM1lBTSIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTQwNjcwOX19fV19&Signature=Ops6To5KF~dZD4ppax87PLGW0DRGedw0ZPZzleerIZULHtkLUaESPdLzFS2~PbxWJ1-uXw3ss~5MEYXN8iOj0FCqzV1KFXlzLHa-Nv9lGKAsHZf-xwq5ORlKvcuNyP49t8uK7tZ4HOOjL7BCH~wpl-KdnrArDtQBTarV0n7jMnb5BIkfUtw-PQPVJYYaiuvrTNOuY0gcuw0fqco8gCn466oLESo8RMQnhrvDKMaRIPjG0wfxC5ppqzqg-ALR2ErAfmwoj6kAs8BSQsLfIaD6Mt0mKH8oANeC-igv~TGh2xbF9dbfNScBSq569iYGFfBD4281AxfU2egZca0nRANRkw__&Key-Pair-Id=K2L8F4GPSG1IFC\", source: hyper_util::client::legacy::Error(Connect, Custom { kind: Other, error: Os { code: 110, kind: TimedOut, message: \"Connection timed out\" } }) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:233\n",
      "\n",
      "  \u001b[2m2025-10-02T11:05:43.170919Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 1.356604085s before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,  # \"google/gemma-2b-it\"\n",
    "    num_labels=2,  # Number of output labels (2 for binary sentiment classification)\n",
    "    id2label=id2label,  # {0: \"NEGATIVE\", 1: \"POSITIVE\"} \n",
    "    label2id=label2id,  # {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "    quantization_config=bnb_config  # configuration for quantization \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8307e-9e95-4762-9b30-ac615ce8ea41",
   "metadata": {},
   "source": [
    "## Fine-Tuning with LoRA Adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c14aa9-ab4a-4525-8568-6f59a03f8ef3",
   "metadata": {},
   "source": [
    "زمانی از prepare_model_for_kbit_training استفاده کنید که:\n",
    "\n",
    "    حافظه GPU محدود دارید\n",
    "    می‌خواهید سرعت آموزش را افزایش دهید\n",
    "    با مدل‌های خیلی بزرگ کار می‌کنید\n",
    "    از کوانتیزاسیون 8-bit استفاده می‌کنید\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86519aa-5ee7-41d4-944f-c37be5c1afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d31dc-cac4-42a0-a007-279ccee21969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_linear_names(model):\n",
    "    \"\"\"\n",
    "    This function identifies all linear layer names within a model that use 4-bit quantization.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The PyTorch model to inspect.\n",
    "    Returns:\n",
    "        list: A list containing the names of all identified linear layers with 4-bit quantization.\n",
    "    \"\"\"\n",
    "    cls = bnb.nn.Linear4bit  \n",
    "\n",
    "    # Set to store identified layer names\n",
    "    lora_module_names = set()\n",
    "\n",
    "    # Iterate through named modules in the model\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the current module is an instance of the 4-bit linear layer class\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "        # Special case: remove 'lm_head' if present\n",
    "        if 'lm_head' in lora_module_names: \n",
    "            lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "# Example usage:\n",
    "modules = find_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc72bc31-1261-45b3-ba36-9439ef469d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=64,  # Reduction factor (lower r means more parameters in the adapter)\n",
    "    lora_alpha=32,  # Dimensionality of the adapter projection\n",
    "    target_modules=modules,  # List of modules to apply the LoRA adapter\n",
    "    lora_dropout=0.05,  # Dropout rate for the adapter\n",
    "    bias=\"none\",  # Bias configuration for the adapter\n",
    "    task_type=\"SEQ_CLS\"  # Task type (sequence classification in this case)\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1326f71-31cd-4117-abf7-fdce70256e48",
   "metadata": {},
   "source": [
    "## Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684e45e-8b58-4821-b1fa-8883a9b954e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"epoch_weights\",  # Output directory for checkpoints\n",
    "    learning_rate=2e-5,  # Learning rate for the optimizer\n",
    "    per_device_train_batch_size=1,  # Batch size per device\n",
    "    per_device_eval_batch_size=1,  # Batch size per device for evaluation \n",
    "    num_train_epochs=5,  # Number of training epochs\n",
    "    weight_decay=0.01,  # Weight decay for regularization\n",
    "    eval_strategy='epoch',  # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",  # Save model checkpoints after each epoch\n",
    "    load_best_model_at_end=True,  # Load the best model based on the chosen metric\n",
    "    push_to_hub=False,  # Disable pushing the model to the Hugging Face Hub \n",
    "    report_to=\"none\",  # Disable logging to Weight&Bias\n",
    "    metric_for_best_model='eval_loss'  # Metric for selecting the best model \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160d293-a289-41b7-adde-fc5ddc167dbd",
   "metadata": {},
   "source": [
    "## Early Stopping (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b147f-bf88-473f-b1ad-3b05c2d2f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStoppingCallback(early_stopping_patience=1, early_stopping_threshold=.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c83ae1-5000-412e-8221-cb4cb78014c4",
   "metadata": {},
   "source": [
    "## Starting the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7d960-d573-4619-854f-900376e0ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,  # The LoRA-adapted model\n",
    "    args=training_args,  # Training arguments\n",
    "    train_dataset=tokenized_imdb[\"train\"],  # Training dataset\n",
    "    eval_dataset=tokenized_imdb[\"test\"],  # Evaluation dataset\n",
    "    tokenizer=tokenizer,  # Tokenizer for processing text\n",
    "    data_collator=data_collator,  # Data collator for preparing batches\n",
    "    compute_metrics=compute_metrics,  # Function to calculate evaluation metrics\n",
    "    callbacks=[early_stop]  # Optional early stopping callback\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35444907-987c-429e-8cc0-458548e92d6e",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c934b6-f829-4f70-a538-ba88df2d012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_path=\"./peft-gemma-imdb\"\n",
    "\n",
    "trainer.model.save_pretrained(peft_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef812d-0b48-4cf5-9a42-156c7d253e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faebcd23-f41a-4615-bc2a-5b3b993d62fd",
   "metadata": {},
   "source": [
    "## load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f811a3-6bf4-4736-8368-2c9f80a5f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "   peft_model_path, num_labels=2, \n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75675e5e-ff1c-4721-ba59-2d00c9a272a1",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01545e-fa07-49a3-827c-3cf0e2a896d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment label for a given text input.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The text to predict the sentiment for.\n",
    "\n",
    "    Returns:\n",
    "        float: The predicted probability of the text being positive sentiment.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")  # Convert to PyTorch tensors and move to GPU (if available)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits  # Get the model's output logits\n",
    "    y_prob = torch.sigmoid(outputs).tolist()[0]  # Apply sigmoid activation and convert to list\n",
    "    return np.round(y_prob, 5)  # Round the predicted probability to 5 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df98d01d-c950-4b19-88ae-b15b5c189a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"The movie was the best movie I have ever seen!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea97ed1-3ce9-4845-b331-0aa1f41c2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"The movie was perfect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8bfb5-5873-4f35-bf10-aa8b31b75b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"The movie was boring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54166fb-6478-45d8-825c-b31c5a3e50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"The movie was not bad, it was good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b91ab9-e66b-40ef-9936-87a5ac16e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"The movie was not good, it was bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9d4e9-c53c-4411-8bf5-00eb5cdfdc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(dataset_imdb['test']).head(10) \n",
    "\n",
    "df_test['prediction'] = df_test['text'].map(predict)\n",
    "df_test['y_pred'] = df_test['prediction'].apply(lambda x: np.argmax(x, axis=0))\n",
    "accuracy = (df_test['y_pred'] == df_test['label']).mean()\n",
    "print(f\"Model Accuracy on Test Data: {accuracy:.4f}\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ee4dd-7450-4bb4-89e9-a0cdf8c08330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
