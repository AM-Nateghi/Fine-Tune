{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1muser: \u001b[0m AM-Nateghi\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "hf_token = '' # put your User Access Tokens here\n",
    "# ابتدا login کنید\n",
    "huggingface_hub.login(token=hf_token)\n",
    "\n",
    "# سپس وضعیت ورود را بررسی کنید\n",
    "!hf auth whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff9a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Text Normalization\n",
    "# ================================================================\n",
    "ARABIC_TO_PERSIAN = {\"\\u064a\": \"ی\", \"\\u0643\": \"ک\", \"\\u06cc\": \"ی\"}\n",
    "PERSIAN_DIGITS_TO_EN = {f\"۰۱۲۳۴۵۶۷۸۹\"[i]: str(i) for i in range(10)}\n",
    "\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize Persian text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    for ar, fa in ARABIC_TO_PERSIAN.items():\n",
    "        text = text.replace(ar, fa)\n",
    "    for fa, en in PERSIAN_DIGITS_TO_EN.items():\n",
    "        text = text.replace(fa, en)\n",
    "    text = \" \".join(text.split())\n",
    "    text = text.replace(\" ؟\", \"؟\").replace(\"،\", \"، \")\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4de4953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/Desktop/Fine-Tune/.env/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:693: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['model.embed_tokens'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "cptk = \"google/gemma-3-270m\"\n",
    "\n",
    "# بارگذاری tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"outputs/gemma3_safe/final/\")\n",
    "# بارگذاری مدل پایه\n",
    "base_model = AutoModelForCausalLM.from_pretrained(cptk)\n",
    "# بارگذاری LoRA روی مدل پایه\n",
    "model = PeftModel.from_pretrained(base_model, \"outputs/gemma3_safe/final/\")\n",
    "# انتقال به GPU\n",
    "model.to(\"cuda\")\n",
    "print(\"ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149b75c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سوال: برام اثبات کن که خدا وجود داره. خیلی خلاصه زود تند سریع.\n",
      "پاسخ: ًآیا خب میاد خدا منطقه ی خدا رو درک نمیکنه؟ یا اگه خدا در بین خدا ها داخل عالم واقعا چقدر درک میفهם؟\n",
      "چرا؟ یا خب میاد دیگه چرا کسی رو درک نمیفهم؟!\n",
      "مثلا یک بیمار مبتلا به جگر شده در اتاق طباب، پزشک بیمار گفته: چطور این انسان جگر رو در میفته؟ آیا شما هم عینک خودتان رو ببینید؟ خب مردم میگن انسان خدا در همه عالم هستی هست چرا مردم میگن ما در عالم واقع هستی هست؟ فقط خود من میگم خدا عالم واقعیه نه خدا عالم های دیگر میگه عالم واقعیه، عینک من نیست؟ اینطور نیست یا خب نمیشه؟ نمیتونه اینطور نیست نمیتونه خدا عالم نیست یعنی خیلی ها فکر کردن براش نیست میگن دنیا در بین ما نیست. همین سوال ها میگئن؟ چرا وقتی ما کسی را در می فرستم و به خاطر این روز گمشده میفهمیم که عالم ها عالم نیست و در واقع عالم واقعیه هستی؟\n",
      "چشمگجابند چطوری میبینیم که دنیا عالم نیست؟ تو این خط دفاعی میگند عالم واقعیه نیست که عالم عالم واقعیه نیست وگر بگو خدا در تمام عالم دنیا هست و چرا دنیا عالم نیست؟ چون عالم در بین خدا ها عالم نیست و عالم های دیگری عالم هم هست و عالم دیگر عالمی هستند هر چند عالم آخر چطوری عالم واقعیه هست و عالم خدا نیست و عالم دیگر عالم واقعیه نیست. چرا عالم آخر عالم آخر هم نیست؟ ولی عالم آخر عالم آخر دیگر عالم آخر هم نیست چرا؟\n",
      "مثلا عالم آخر عالم آخر عالم آخر بین خدا ها عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالمآخر عالم\n"
     ]
    }
   ],
   "source": [
    "q_norm = normalize_text(\"برام اثبات کن که خدا وجود داره. خیلی خلاصه زود تند سریع.\")\n",
    "text = f\"سوال: {q_norm}\\nپاسخ: \"\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        **tokenizer(text, return_tensors=\"pt\").to(\n",
    "            \"cuda\"\n",
    "        ),\n",
    "        max_new_tokens=512,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
